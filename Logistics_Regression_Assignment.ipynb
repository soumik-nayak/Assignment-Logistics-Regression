{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LOGISTIC REGRESSION Questions\n"
      ],
      "metadata": {
        "id": "cmg0EKO5dCyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#THEORY"
      ],
      "metadata": {
        "id": "7wahasx6dMsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "Logistic Regression is a supervised learning algorithm used for **classification tasks**. It predicts the probability of a class using the **sigmoid function**, unlike Linear Regression, which predicts continuous values.\n",
        "\n",
        "**Differences:**\n",
        "- **Linear Regression**: Predicts continuous values.\n",
        "- **Logistic Regression**: Predicts probabilities for categorical outcomes.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. What is the mathematical equation of Logistic Regression?\n",
        "\n",
        "The equation is:\n",
        "\n",
        "\\[\n",
        "P(Y=1 | X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n)}}\n",
        "\\]\n",
        "\n",
        "where:\n",
        "- \\( P(Y=1 | X) \\) is the probability of the positive class.\n",
        "- \\( \\beta_0 \\) is the intercept.\n",
        "- \\( \\beta_1, \\beta_2, ..., \\beta_n \\) are feature coefficients.\n",
        "- \\( e \\) is Euler’s number.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        "The **sigmoid function**:\n",
        "\n",
        "\\[\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "\\]\n",
        "\n",
        "is used because:\n",
        "- It converts any real number into a probability (0 to 1).\n",
        "- It provides a smooth gradient for optimization.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. What is the cost function of Logistic Regression?\n",
        "\n",
        "Instead of Mean Squared Error (MSE), Logistic Regression uses **log loss (cross-entropy loss)**:\n",
        "\n",
        "\\[\n",
        "J(\\beta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
        "\\]\n",
        "\n",
        "where \\( \\hat{y}_i \\) is the predicted probability.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        "Regularization prevents **overfitting** by adding a penalty term to the cost function.\n",
        "\n",
        "- **L1 (Lasso)**: Shrinks some coefficients to zero (feature selection).\n",
        "- **L2 (Ridge)**: Shrinks coefficients but keeps all features.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "\n",
        "| Regularization | Penalty Term | Effect |\n",
        "|---------------|-------------|--------|\n",
        "| **Lasso (L1)** | \\( \\lambda \\sum |\\beta_j| \\) | Eliminates some features |\n",
        "| **Ridge (L2)** | \\( \\lambda \\sum \\beta_j^2 \\) | Shrinks coefficients without eliminating |\n",
        "| **Elastic Net** | \\( \\lambda_1 \\sum |\\beta_j| + \\lambda_2 \\sum \\beta_j^2 \\) | Mix of Lasso & Ridge |\n",
        "\n",
        "---\n",
        "\n",
        "## 7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        "- When there are **many correlated features**.\n",
        "- When we need both **feature selection (L1)** and **shrinkage (L2)**.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
        "\n",
        "- **Higher λ** → More regularization → Avoids overfitting.\n",
        "- **Lower λ** → Less regularization → Risk of overfitting.\n",
        "- **Too high λ** → Can cause underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. What are the key assumptions of Logistic Regression?\n",
        "\n",
        "- **Linear relationship** between independent variables and log-odds.\n",
        "- **No multicollinearity**.\n",
        "- **Large sample size**.\n",
        "- **Independence of observations**.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        "- **Decision Trees**\n",
        "- **Random Forest**\n",
        "- **Support Vector Machines (SVM)**\n",
        "- **Naïve Bayes**\n",
        "- **Neural Networks**\n",
        "\n",
        "---\n",
        "\n",
        "## 11. What are Classification Evaluation Metrics?\n",
        "\n",
        "- **Accuracy** = \\( \\frac{\\text{Correct Predictions}}{\\text{Total Predictions}} \\)\n",
        "- **Precision** = \\( \\frac{TP}{TP + FP} \\)\n",
        "- **Recall** = \\( \\frac{TP}{TP + FN} \\)\n",
        "- **F1-Score** = \\( 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\)\n",
        "- **ROC-AUC Score** (for model performance evaluation).\n",
        "\n",
        "---\n",
        "\n",
        "## 12. How does class imbalance affect Logistic Regression?\n",
        "\n",
        "- The model may be biased toward the majority class.\n",
        "- **Solutions**:\n",
        "  - Oversampling minority / undersampling majority class.\n",
        "  - Weighted loss functions.\n",
        "  - Trying alternative models (e.g., Random Forest).\n",
        "\n",
        "---\n",
        "\n",
        "## 13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        "Optimizing parameters like:\n",
        "- **Regularization strength (λ)**\n",
        "- **Solver selection** (`liblinear`, `lbfgs`, etc.)\n",
        "- **Penalty type (L1, L2, Elastic Net)**\n",
        "\n",
        "Methods:\n",
        "- **Grid Search**\n",
        "- **Random Search**\n",
        "- **Bayesian Optimization**\n",
        "\n",
        "---\n",
        "\n",
        "## 14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        "| Solver | Supports L1 | Supports L2 | Multiclass | Best Use Case |\n",
        "|--------|------------|------------|------------|---------------|\n",
        "| **liblinear** | ✅ | ✅ | No | Small datasets |\n",
        "| **lbfgs** | ❌ | ✅ | Yes | Large datasets |\n",
        "| **saga** | ✅ | ✅ | Yes | Sparse data |\n",
        "| **newton-cg** | ❌ | ✅ | Yes | Smooth optimization |\n",
        "\n",
        "---\n",
        "\n",
        "## 15. How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        "Two approaches:\n",
        "- **One-vs-Rest (OvR)**: Trains a separate model per class.\n",
        "- **Softmax Regression**: Uses the softmax function to output class probabilities.\n",
        "\n",
        "---\n",
        "\n",
        "## 16. What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        "✅ **Advantages**:\n",
        "- Simple and interpretable.\n",
        "- Works well with small datasets.\n",
        "- Fast and computationally efficient.\n",
        "\n",
        "❌ **Disadvantages**:\n",
        "- Assumes linearity in log-odds.\n",
        "- Struggles with complex patterns.\n",
        "- Sensitive to multicollinearity.\n",
        "\n",
        "---\n",
        "\n",
        "## 17. What are some use cases of Logistic Regression?\n",
        "\n",
        "- **Spam detection**\n",
        "- **Medical diagnosis (disease prediction)**\n",
        "- **Credit risk assessment**\n",
        "- **Customer churn prediction**\n",
        "- **Fraud detection**\n",
        "\n",
        "---\n",
        "\n",
        "## 18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "\n",
        "- **Logistic Regression**: Binary classification.\n",
        "- **Softmax Regression**: Multiclass classification.\n",
        "\n",
        "---\n",
        "\n",
        "## 19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "\n",
        "- **OvR**: Works well for imbalanced datasets.\n",
        "- **Softmax**: Better when classes are balanced.\n",
        "\n",
        "---\n",
        "\n",
        "## 20. How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "- **Positive coefficient** → Increases log-odds of positive class.\n",
        "- **Negative coefficient** → Decreases log-odds of positive class.\n",
        "- \\( e^{\\beta_j} \\) represents the **odds ratio**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "2o3crCvBdlwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PRACTICAL"
      ],
      "metadata": {
        "id": "sSk8XnpvfSmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 0).astype(int)  # Binary classification: Class 0 vs Rest\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWnE-d5Pieoi",
        "outputId": "86db2249-56ad-4407-e550-d7d9ec869623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2: Apply L1 regularization (Lasso) using LogisticRegression(penalty='l1') and print the model accuracy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model with L1 regularization\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSjHvqSxifbT",
        "outputId": "48cfc8ef-1014-444c-b03d-15cdd03a962a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3: Train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2')\n",
        "# Print model accuracy and coefficients\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y = (X[:, 0] + X[:, 1] > 1).astype(int)  # Simple decision boundary\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "id": "EF6a26nGjOLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511c8dee-c3d7-4145-bb43-ef8598a26c21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9000\n",
            "Model Coefficients:\n",
            "[[ 2.46284943e+00  2.24599684e+00 -3.18805624e-01 -4.11842850e-01\n",
            "   2.79252046e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4: Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n",
        "# Print the model accuracy and coefficients.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(200, 5)  # 200 samples, 5 features\n",
        "y = np.random.randint(0, 2, 200)  # Binary target variable (0 or 1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with Elastic Net regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)  # l1_ratio=0.5 balances L1 and L2\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnAxfWa5gATR",
        "outputId": "07f4d967-fdfa-4810-e7c8-b816527673eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.675\n",
            "Model Coefficients: [[-0.22713439 -0.47460495 -0.03776566 -0.37159168 -0.07156835]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n",
        "# Print the model accuracy and coefficients.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset for multiclass classification\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(300, 5)  # 300 samples, 5 features\n",
        "y = np.random.randint(0, 3, 300)  # Multiclass target variable (0, 1, or 2)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model for multiclass classification using 'ovr'\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-whng1cgYST",
        "outputId": "87159992-2b6c-418f-c45b-e56307812456"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.38333333333333336\n",
            "Model Coefficients: [[ 0.06846004  0.05121364 -0.07603563  0.18325763  0.06755312]\n",
            " [ 0.05841134  0.01429321 -0.06461146 -0.04794319 -0.09242482]\n",
            " [-0.13827709 -0.06707412  0.15479421 -0.14178467  0.03422119]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6 . Question: Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression.\n",
        "# Print the best parameters and accuracy.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(200, 5)  # 200 samples, 5 features\n",
        "y = np.random.randint(0, 2, 200)  # Binary target variable (0 or 1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define Logistic Regression model\n",
        "model = LogisticRegression(solver='saga', max_iter=500)\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],  # Regularization type\n",
        "    'l1_ratio': [0.2, 0.5, 0.8]  # Only used for 'elasticnet'\n",
        "}\n",
        "\n",
        "# Perform Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters and evaluate on test data\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Test Set Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey3Zw7hlgi9C",
        "outputId": "1a741305-57ad-412d-e510-7f02bef5275e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.1, 'l1_ratio': 0.8, 'penalty': 'elasticnet'}\n",
            "Test Set Accuracy: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Question 7: Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation.\n",
        "# Print the average accuracy.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(200, 5)  # 200 samples, 5 features\n",
        "y = np.random.randint(0, 2, 200)  # Binary target variable (0 or 1)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Define Logistic Regression model\n",
        "model = LogisticRegression(solver='lbfgs', max_iter=500)\n",
        "\n",
        "# Define Stratified K-Fold cross-validator\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and compute accuracy\n",
        "accuracies = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-Validation Accuracies:\", accuracies)\n",
        "print(\"Average Accuracy:\", np.mean(accuracies))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBRUXTkggqPl",
        "outputId": "96591e7a-996a-476a-ce44-667060aec251"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracies: [0.7   0.525 0.525 0.65  0.6  ]\n",
            "Average Accuracy: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression.\n",
        "# Print the best parameters and accuracy.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create dataset\n",
        "X = np.random.rand(200, 5)\n",
        "y = np.random.randint(0, 2, 200)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model and hyperparameters\n",
        "model = LogisticRegression(max_iter=500)\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "\n",
        "# Apply RandomizedSearchCV\n",
        "search = RandomizedSearchCV(model, param_grid, n_iter=5, cv=3, scoring='accuracy', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", search.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, search.best_estimator_.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJuYeijxhfAC",
        "outputId": "d96746dc-28b6-4fe8-80ce-2f7257ef3a19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 10}\n",
            "Accuracy: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 10: Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X = np.random.rand(300, 5)\n",
        "y = np.random.randint(0, 3, 300)  # 3 classes\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(multi_class='ovo', solver='lbfgs', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "q1RNjuJbhv3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 11: Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and compute confusion matrix\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "jrD5_VR2h0mC",
        "outputId": "32aa3cdc-04e5-4cf7-9199-8a89a3d82a07"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAGwCAYAAAD8AYzHAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALF9JREFUeJzt3XlcVXX+x/H3BeWKiAgoCrlRlriQueU2uZSTWqOSk/5qWkgbK3fFSumXW47ecloc06QaU1tc5pdLjpWTYyk5brlmo2GWqbnjAoFyJbi/P3pE3UCD4zkcOL6ePs7j0T3ncs7n+rB89/l8z7kun8/nEwAAgAEBdhcAAADKL4IEAAAwjCABAAAMI0gAAADDCBIAAMAwggQAADCMIAEAAAwjSAAAAMMq2F2AFU5k5tpdAsqY1v/7od0loAwZd38zu0tAGTKwTT3LrxHcfKgp57mwY6Yp5zETHQkAAGCYIzsSAACUKS7n/n87QQIAAKu5XHZXYBmCBAAAVnNwR8K5nwwAAFiOjgQAAFZjtAEAAAxjtAEAAFAYHQkAAKzGaAMAABjGaAMAAKAwOhIAAFiN0QYAADCM0QYAAEBhdCQAALAaow0AAGCYg0cbBAkAAKzm4I6EcyMSAACwHB0JAACsxmgDAAAY5uAg4dxPBgAALEdHAgAAqwU4d7ElQQIAAKsx2gAAACiMIAEAgNVcLnO2EkpNTVXPnj0VExMjl8ul5cuXFxzLzc3VmDFjFB8fr5CQEMXExOjBBx/U0aNHS3QNggQAAFZzBZizlVB2draaNWumWbNmFTp2/vx5bd++XePGjdP27du1dOlSpaWlqVevXiW6BmskAABwqB49eqhHjx5FHgsLC9Pq1av99s2cOVM333yzDh06pLp16xbrGgQJAACsZtIjsr1er7xer98+t9stt9ttyvkzMjLkcrlUrVq1Yv8Mow0AAKxm0mjD4/EoLCzMb/N4PKaUmJOTozFjxujee+9V1apVi/1zdCQAALCaSR2J5ORkJSUl+e0zoxuRm5urfv36yefzafbs2SX6WYIEAADlhJljjJ/8FCIOHjyojz/+uETdCIkgAQCA9croA6l+ChFfffWVPvnkE0VGRpb4HAQJAACsZtJoo6SysrK0f//+gtcHDhzQzp07FRERoejoaN19993avn27Vq5cqby8PB0/flySFBERoaCgoGJdgyABAIBDbd26VV26dCl4/dP6isTERE2cOFErVqyQJN10001+P/fJJ5+oc+fOxboGQQIAAKvZNNro3LmzfD7fJY9f7lhxESQAALCaTaON0lA2V38AAIBygY4EAABWK6N3bZiBIAEAgNUcHCSc+8kAAIDl6EgAAGA1By+2JEgAAGA1B482CBIAAFjNwR0J50YkAABgOToSAABYjdEGAAAwjNEGAABAYXQkAACwmMvBHQmCBAAAFnNykGC0AQAADKMjAQCA1ZzbkCBIAABgNUYbAAAARaAjAQCAxZzckSBIAABgMYIEAAAwjCCBcmXn9q1a9NZcpX25R6fTT2nKX/+mWzrfZndZKAU3Xxehx25roPi61VQzrJL+/PoWffT5cb/3JN3RUH9qX09Vgytq64Ezemrx5/r2VLZNFaO0/Wfpm9q4/G2/fRHRtTXguTdsqgjlHUHCgXIuXNB1NzTUHb3u0tNPjrS7HJSiyu4K2nMkU4s3HdLrA28udHxQ1wbq3+laJb29Q4dPn9fjdzbU24Pb6rYpn8j7Q74NFcMOkdfUU78xzxW8dgUG2ljNVcK5DQmChBO17XCL2na4xe4yYIO1e05q7Z6Tlzz+cOdr9fK/9mn17h+7FKPe2qFtU7vp9htr6Z/bj5ZWmbBZQGCgQqpF2F3GVYXRhkXS09P1xhtvaOPGjTp+/Mf/sNWqVUvt27fXQw89pBo1athZHuAodSMrKyqsktannSrY933OD9r57Vm1jI0gSFxFzh4/otnD71GFikGKadBIt/R9WFWrR9ldFsop254j8dlnn+mGG27QjBkzFBYWpo4dO6pjx44KCwvTjBkzFBcXp61bt/7mebxerzIzM/02r9dbCp8AKF9qVHVLktK/9//3I/17b8ExOF/0dXHq8cgTuvvxqeqaOFwZp05o4ZQkXbxw3u7SHM3lcpmylUW2dSSGDRumvn37KiUlpdBvjs/n02OPPaZhw4Zp48aNlz2Px+PRpEmT/PaNHvu0nkgeb3rNAFDeXdvs57UzNepeq+jr4vRa0v1K27JO8Z162FiZs5XVEGAG24LErl27NG/evCJ/c10ul0aNGqXmzZv/5nmSk5OVlJTkt++clwd2Ar92KvPHTkT1ULdOZv7clage6taeI5l2lQWbVQqpovBatXX2BKMtGGPb37i1atXSli1bLnl8y5Ytqlmz5m+ex+12q2rVqn6b202bFvi1Q6fP62RGjjo0/HntUZVKFXRT/XBtO3DGxspgp4s5F5Rx8piqsPjSUow2LPD444/rkUce0bZt23TbbbcVhIYTJ05ozZo1ev311/X888/bVV65dv78eR05fKjg9bGjR/RV2peqGhammrWibawMVqscFKj6NUIKXteJrKzG11TVufO5Onr2guas/UbDu12vb09m6dDp83r8D3E6mZFT6FkTcK61C1/Tdc3bqmpklLLOndaGpW/KFRCguLZd7C7N2cpmBjCFbUFiyJAhql69ul566SW98sorysvLkyQFBgaqZcuWmjdvnvr162dXeeVa2t4vNOKxAQWvZ740TZLU/c7eemriFLvKQim4sW41/WNEh4LXE/o0lST93+ZDGv32Ts3+934FBwXKc2+zHx9I9c0ZPfDKJp4hcRX5/swprXxlqnKyvldwaJiuuaGJ7hv/N1WuWs3u0lBOuXw+n8/uInJzc5Weni5Jql69uipWrHhF5zuRmWtGWXCQ1v/7od0loAwZd38zu0tAGTKwTT3Lr1H9oUWmnCd93j2mnMdMZeKBVBUrVlR0NC13AIAzldX1DWYoE0ECAAAnc3KQ4D5JAABgGB0JAACs5tyGBEECAACrMdoAAAAoAh0JAAAs5uSOBEECAACLOTlIMNoAAACG0ZEAAMBiTu5IECQAALCac3MEow0AAGAcHQkAACzGaAMAABjm5CDBaAMAAIu5XC5TtpJKTU1Vz549FRMTI5fLpeXLl/sd9/l8Gj9+vKKjoxUcHKyuXbvqq6++KtE1CBIAADhUdna2mjVrplmzZhV5fNq0aZoxY4ZSUlK0efNmhYSEqFu3bsrJySn2NRhtAABgNZMmG16vV16v12+f2+2W2+0u8v09evRQjx49ijzm8/k0ffp0Pf300+rdu7ck6c0331TNmjW1fPly3XPPPcWqiY4EAAAWM2u04fF4FBYW5rd5PB5DNR04cEDHjx9X165dC/aFhYWpTZs22rhxY7HPQ0cCAIByIjk5WUlJSX77LtWN+C3Hjx+XJNWsWdNvf82aNQuOFQdBAgAAi5l118blxhh2YbQBAIDF7Lpr43Jq1aolSTpx4oTf/hMnThQcKw6CBAAAV6HY2FjVqlVLa9asKdiXmZmpzZs3q127dsU+D6MNAAAsZtcDqbKysrR///6C1wcOHNDOnTsVERGhunXrauTIkfrLX/6i66+/XrGxsRo3bpxiYmKUkJBQ7GsQJAAAsJpND7bcunWrunTpUvD6p4WaiYmJmjdvnp588kllZ2frkUce0blz5/S73/1Oq1atUqVKlYp9DYIEAAAO1blzZ/l8vksed7lceuaZZ/TMM88YvgZBAgAAizn5uzYIEgAAWIwgAQAADHNwjuD2TwAAYBwdCQAALMZoAwAAGObgHMFoAwAAGEdHAgAAizHaAAAAhjk4RzDaAAAAxtGRAADAYgEBzm1JECQAALAYow0AAIAi0JEAAMBi3LUBAAAMc3COIEgAAGA1J3ckWCMBAAAMoyMBAIDFnNyRIEgAAGAxB+cIRhsAAMA4OhIAAFiM0QYAADDMwTmC0QYAADCOjgQAABZjtAEAAAxzcI5gtAEAAIyjIwEAgMUYbQAAAMMcnCMIEgAAWM3JHQnWSAAAAMMc2ZEIq1zR7hJQxpxa/5HdJaAMeTw9w+4SUIYMXPiA5ddwcEPCmUECAICyhNEGAABAEehIAABgMQc3JAgSAABYjdEGAABAEehIAABgMQc3JAgSAABYjdEGAABAEehIAABgMSd3JAgSAABYzME5giABAIDVnNyRYI0EAAAwjI4EAAAWc3BDgiABAIDVGG0AAAAUgSABAIDFXC5ztpLIy8vTuHHjFBsbq+DgYF133XWaPHmyfD6fqZ+N0QYAABYLsGG08dxzz2n27NmaP3++mjRpoq1bt6p///4KCwvT8OHDTbsOQQIAgHLC6/XK6/X67XO73XK73YXeu2HDBvXu3Vt33nmnJKl+/fpauHChtmzZYmpNjDYAALCYWaMNj8ejsLAwv83j8RR5zfbt22vNmjXat2+fJGnXrl1av369evToYepnoyMBAIDFzLprIzk5WUlJSX77iupGSNLYsWOVmZmpuLg4BQYGKi8vT1OmTNF9991nSi0/IUgAAGCxAJOWSFxqjFGUf/zjH3rnnXe0YMECNWnSRDt37tTIkSMVExOjxMREcwoSQQIAAEd64oknNHbsWN1zzz2SpPj4eB08eFAej4cgAQBAeWLHA6nOnz+vgAD/pZCBgYHKz8839ToECQAALGbHgy179uypKVOmqG7dumrSpIl27NihF198UQMGDDD1OgQJAAAc6OWXX9a4ceM0ePBgnTx5UjExMXr00Uc1fvx4U69DkAAAwGIulX5LIjQ0VNOnT9f06dMtvQ5BAgAAi5l110ZZxAOpAACAYXQkAACwmJO/RpwgAQCAxRycIxhtAAAA4+hIAABgMTu+Rry0ECQAALCYg3MEQQIAAKs5ebElayQAAIBhdCQAALCYgxsSBAkAAKzm5MWWjDYAAIBhdCQAALCYc/sRBAkAACzHXRsAAABFoCMBAIDFnPw14gQJAAAs5uTRRrGCxIoVK4p9wl69ehkuBgAAlC/FChIJCQnFOpnL5VJeXt6V1AMAgOM4uCFRvCCRn59vdR0AADjWVT/aAAAAxrHY8leys7O1bt06HTp0SBcvXvQ7Nnz4cFMKAwAAZV+Jg8SOHTt0xx136Pz588rOzlZERITS09NVuXJlRUVFESQAAPgVJ482SvxAqlGjRqlnz546e/asgoODtWnTJh08eFAtW7bU888/b0WNAACUay6TtrKoxEFi586dGj16tAICAhQYGCiv16s6depo2rRpeuqpp6yoEQAAlFElDhIVK1ZUQMCPPxYVFaVDhw5JksLCwnT48GFzqwMAwAECXC5TtrKoxGskmjdvrs8++0zXX3+9OnXqpPHjxys9PV1vvfWWmjZtakWNAACUa2U0A5iixB2JqVOnKjo6WpI0ZcoUhYeHa9CgQTp16pRee+010wsEAABlV4k7Eq1atSr456ioKK1atcrUggAAcBon37XBA6kAALCYg3NEyYNEbGzsZZPVN998c0UFwRyLFryj+XPnKD39lG5oGKexT41T/I032l0WLNahxXUa9WBXtWhcV9E1wtRv1Gv659rPC47/76N3qG+3FqpdK1wXc/O0Y+8hTZz5T332xUEbq4aV2sdFafgfmuimayMUHV5Zf3phrd7f+vPC+J6t62hA1xt0U2ykIkLd+t3Yldp98KyNFaO8KXGQGDlypN/r3Nxc7dixQ6tWrdITTzxhVl24Aqs+/EDPT/Po6QmTFB/fTO+8NV+DHn1Y761cpcjISLvLg4VCgt3ave+I3nxvoxa/+Eih4/sPntSo5/5PB75LV7C7oobdf6v++cpQNe09Selns2yoGFar7K6gLw6d1dtr9+ud0Z2LPL4x7aSWbTqolx9pV/oFXiXK6h0XZihxkBgxYkSR+2fNmqWtW7decUG4cm/Nn6s+d/dTwl1/lCQ9PWGSUlPXavnSJXp4YOG/XOAcH/1njz76z55LHl+8yv/f0TEvLFX/u9qr6fUxWrtln9XlwQb/3nVU/9519JLHF68/IEmqWz2ktEq6Kjk4R5T8ro1L6dGjh5YsWWLW6WBQ7sWL2rvnv2rbrn3BvoCAALVt216f79phY2UoaypWCNTDfTro3PfntXvfEbvLARzN5XKZspVFpgWJd999VxEREWadTpJ0+PBhDRgw4LLv8Xq9yszM9Nu8Xq+pdZQnZ8+dVV5eXqERRmRkpNLT022qCmVJj1ua6tR/XtC5zS9p2P1d9IfHZur0uWy7ywJQTpU4SDRv3lwtWrQo2Jo3b67o6Gg99dRTpj8i+8yZM5o/f/5l3+PxeBQWFua3/fU5j6l1AE6y7rN9anOPR10eelEfbdijt6cNUI3wKnaXBThagElbWVTiNRK9e/f2a68EBASoRo0a6ty5s+Li4kp0rhUrVlz2eHHuAElOTlZSUpLfPl+gu0R1OEl4tXAFBgbq9OnTfvtPnz6t6tWr21QVypLzORf1zeF0fXM4XVt2f6vd741X4l3t9fwbH9ldGuBYZXUsYYYSB4mJEyeadvGEhAS5XC75fL5Lvue3fvPdbrfcbv/gkPODKeWVSxWDgtSocRNt3rRRt97WVZKUn5+vzZs36p5777e5OpRFAS6X3BV5pAwAY0r8X4/AwEAdO3ZMUVFRfvtPnz6tqKgo5eXlFftc0dHReuWVV9S7d+8ij+/cuVMtW7YsaYlXvQcS+2vcU2PUpElTNY2/UW+/NV8XLlxQwl197C4NFgsJDtJ1dWoUvK5/TaRuvOEanc08r9PnsjXmz930/rrdOp6eochqVfRov46Kiaqmpau321g1rBTirqBra4UWvK5Xo4ri64XrbJZX350+r/CQINWuHqJa4cGSpOujq0qSTpy7oJMZObbU7EQBzm1IlDxIXKp74PV6FRQUVKJztWzZUtu2bbtkkPitbgWK1r3HHTp75oxemTlD6emn1DCukV559e+KZLTheC0a19NHf//5Fu1pj/94C/BbKzZp2JRFali/pu7v2UaR1UJ0JuO8tv73oLoOeEl7vzluV8mwWPNrI/X++NsLXnse/PFrDt5Z97UGp2xQj5a1NXtQh4Ljc0d0/PF97+7Ss0s+F8zh5CDh8hXzb+oZM2ZIkkaNGqXJkyerSpWfF2fl5eUpNTVV3377rXbsKP4thp9++qmys7PVvXv3Io9nZ2dr69at6tSpU7HPKV3dow0ULbz1ULtLQBkSFNfG7hJQhmQsfMDyaySt+NKU87zYq2RrEUtDsTsSL730kqQfOxIpKSkKDAwsOBYUFKT69esrJSWlRBe/5ZZbLns8JCSkxCECAICyhsWWkg4c+PHpZ126dNHSpUsVHh5uWVEAADiJk0cbJV4j8cknn1hRBwAAKIdK/HyLP/7xj3ruuecK7Z82bZr69u1rSlEAADiJy2XOVhaVOEikpqbqjjvuKLS/R48eSk1NNaUoAACcJMDlMmUri0ocJLKysoq8zbNixYrKzMw0pSgAAJzErkdkHzlyRPfff78iIyMVHBys+Ph407+pu8R1xcfHa/HixYX2L1q0SI0bNzalKAAAcGXOnj2rDh06qGLFivrwww+1Z88evfDCC6bfLFHixZbjxo1Tnz599PXXX+vWW2+VJK1Zs0YLFizQu+++a2pxAAA4gVlTCa/XW+gbrov6qghJeu6551SnTh3NnTu3YF9sbKw5hfxCiTsSPXv21PLly7V//34NHjxYo0eP1pEjR/Txxx+rQYMGphcIAEB5Z9YaiaK+8drjKfobr1esWKFWrVqpb9++ioqKUvPmzfX666+b/tmK/WTLS8nMzNTChQs1Z84cbdu2rUTftWEVnmyJX+PJlvglnmyJXyqNJ1uOW/WVKed5ukvdYnckKlWqJElKSkpS37599dlnn2nEiBFKSUlRYmKiKfVIBkYbP0lNTdWcOXO0ZMkSxcTEqE+fPpo1a5ZphQEA4BRmjTYuFRqKkp+fr1atWmnq1KmSpObNm+uLL76wN0gcP35c8+bN05w5c5SZmal+/frJ6/Vq+fLlLLQEAOAS7HiyZXR0dKG/mxs1aqQlS5aYep1ir5Ho2bOnGjZsqM8//1zTp0/X0aNH9fLLL5taDAAAMEeHDh2Ulpbmt2/fvn2qV6+eqdcpdkfiww8/1PDhwzVo0CBdf/31phYBAICT2fEwqVGjRql9+/aaOnWq+vXrpy1btui1117Ta6+9Zup1it2RWL9+vb7//nu1bNlSbdq00cyZM5Wenm5qMQAAOJEdj8hu3bq1li1bpoULF6pp06aaPHmypk+frvvuu8/Uz1bsING2bVu9/vrrOnbsmB599FEtWrRIMTExys/P1+rVq/X999+bWhgAALgyf/jDH7R7927l5ORo7969GjhwoOnXKPFzJEJCQjRgwACtX79eu3fv1ujRo/Xss88qKipKvXr1Mr1AAADKuwCXOVtZZOTR3QUaNmyoadOm6bvvvtPChQvNqgkAAEdxmfSrLDL8HIlfCgwMVEJCghISEsw4HQAAjlJWuwlmuKKOBAAAuLqZ0pEAAACX5uSOBEECAACLuWx4jkRpYbQBAAAMoyMBAIDFGG0AAADDHDzZYLQBAACMoyMBAIDF7PjSrtJCkAAAwGJOXiPBaAMAABhGRwIAAIs5eLJBkAAAwGoBZfQLt8xAkAAAwGJO7kiwRgIAABhGRwIAAIs5+a4NggQAABZz8nMkGG0AAADD6EgAAGAxBzckCBIAAFiN0QYAAEAR6EgAAGAxBzckCBIAAFjNye1/J382AABgMToSAABYzOXg2QZBAgAAizk3RhAkAACwHLd/AgAAFIGOBAAAFnNuP4IgAQCA5Rw82WC0AQAAjKMjAQCAxbj9EwAAGObk9r+TPxsAALAYHQkAACzGaAMAABjm3BjBaAMAAFwBOhIAAFiM0QZQzsUl9LG7BJQh33x5xO4ScJVxcvufIAEAgMWc3JFwckgCAAAWoyMBAIDFnNuPIEgAAGA5B082GG0AAHA1ePbZZ+VyuTRy5EhTz0tHAgAAiwXYPNz47LPP9Oqrr+rGG280/dx0JAAAsJjLZc5mRFZWlu677z69/vrrCg8PN/eDiSABAEC54fV6lZmZ6bd5vd7L/syQIUN05513qmvXrpbURJAAAMBiLpN+eTwehYWF+W0ej+eS1120aJG2b99+2fdcKdZIAABgMbPu2khOTlZSUpLfPrfbXeR7Dx8+rBEjRmj16tWqVKmSOQUUgSABAEA54Xa7Lxkcfm3btm06efKkWrRoUbAvLy9PqampmjlzprxerwIDA6+4JoIEAAAWs+Oujdtuu027d+/229e/f3/FxcVpzJgxpoQIiSABAIDl7HggVWhoqJo2beq3LyQkRJGRkYX2XwmCBAAAFnPyky0JEgAAXCXWrl1r+jkJEgAAWMzl4K/tIkgAAGCxAOfmCB5IBQAAjKMjAQCAxRhtAAAAw5x81wajDQAAYBgdCQAALMZoAwAAGMZdGwAAAEWgIwEAgMUYbQAAAMOcfNcGQQIAAIs5OEewRgIAABhHRwIAAIsFOHi2QZAAAMBizo0RjDYAAMAVoCMBAIDVHNySIEgAAGAxJz9HgtEGAAAwjI4EAAAWc/BNGwQJAACs5uAcwWgDAAAYR0cCAACrObglQZAAAMBiTr5rgyABAIDFnLzYkjUSAADAMDoSAABYzMENCYIEAACWc3CSYLQBAAAMoyMBAIDFuGsDAAAYxl0bAAAARaAjAQCAxRzckCBIAABgOQcnCUYbAADAMDoSAABYjLs2AACAYU6+a4MgAQCAxRycI1gjAQAAjKMjAQCA1RzckiBIONSiBe9o/tw5Sk8/pRsaxmnsU+MUf+ONdpcFG1QOCtTgLtfq1rgaCg+pqLTjWZq2ap/2HP3e7tJQCtrHRWn4H5ropmsjFB1eWX96Ya3e33q44HjP1nU0oOsNuik2UhGhbv1u7ErtPnjWxoqdycmLLRltONCqDz/Q89M8enTwEC36v2Vq2DBOgx59WKdPn7a7NNhgfM84tb02XE8v26N+s7do49dnlPJAc9UIDbK7NJSCyu4K+uLQWT3+xpZLHt+YdlITFm4v5crgFHQkHOit+XPV5+5+Srjrj5KkpydMUmrqWi1fukQPD3zE5upQmtwVAnRb4xoatWi3th86J0l6dd0BdbwhUn1b1dYrn3xjb4Gw3L93HdW/dx295PHF6w9IkupWDymtkq5KTr5rg46Ew+RevKi9e/6rtu3aF+wLCAhQ27bt9fmuHTZWBjsEBrhUISBAF3/I99vv/SFfzeuG2VQVcPVxmbSVRbYHiQsXLmj9+vXas2dPoWM5OTl68803L/vzXq9XmZmZfpvX67Wq3DLv7LmzysvLU2RkpN/+yMhIpaen21QV7HL+Yp52Hc7QwI71VaNKkAJc0h3xNXVj7TBVr8JoA8CVszVI7Nu3T40aNVLHjh0VHx+vTp066dixYwXHMzIy1L9//8uew+PxKCwszG/763Meq0sHyo2nl+2RS9JHo3+nzU931r1t6mjVFyeU77O7MuAq4uCWhK1BYsyYMWratKlOnjyptLQ0hYaGqkOHDjp06FCxz5GcnKyMjAy/7YkxyRZWXbaFVwtXYGBgoYWVp0+fVvXq1W2qCnb67uwF/Xn+DrWbulY9XtqgB/6+VRUCXDpy9oLdpQFXDZdJv0rC4/GodevWCg0NVVRUlBISEpSWlmb6Z7M1SGzYsEEej0fVq1dXgwYN9M9//lPdunXTLbfcom++Kd4iMLfbrapVq/ptbrfb4srLropBQWrUuIk2b9pYsC8/P1+bN2/Ujc2a21gZ7JaTm6/0rIsKrVRB7RtEaG0aoy7AydatW6chQ4Zo06ZNWr16tXJzc3X77bcrOzvb1OvYetfGhQsXVKHCzyW4XC7Nnj1bQ4cOVadOnbRgwQIbqyu/Hkjsr3FPjVGTJk3VNP5Gvf3WfF24cEEJd/WxuzTYoN11EXJJ+vb0edWJCNao3zfQgfTzWrHz2G/+LMq/EHcFXVsrtOB1vRpVFF8vXGezvPru9HmFhwSpdvUQ1QoPliRdH11VknTi3AWdzMixpWYnsuOujVWrVvm9njdvnqKiorRt2zZ17NjRtOvYGiTi4uK0detWNWrUyG//zJkzJUm9evWyo6xyr3uPO3T2zBm9MnOG0tNPqWFcI73y6t8VyWjjqlTFXUHDbrtONau6lXEhV2v2ntKsj7/WDyySuCo0vzZS74+/veC158FWkqR31n2twSkb1KNlbc0e1KHg+NwRP/4F43l3l55d8nnpFutgZuUIr9db6IYCt9tdrE58RkaGJCkiIsKkan7k8vl8tv3XxOPx6NNPP9UHH3xQ5PHBgwcrJSVF+fn5RR6/lJwfzKgOTtJuysd2l4Ay5Jsvj9hdAsqQjIUPWH6NfSfOm3KeBbOnadKkSX77JkyYoIkTJ1725/Lz89WrVy+dO3dO69evN6WWn9gaJKxCkMCvESTwSwQJ/FJ5ChL1qgUa6kgMGjRIH374odavX6/atWubUstPeLIlAAAWM+u7Noo7xviloUOHauXKlUpNTTU9REgECQAALGfHYkufz6dhw4Zp2bJlWrt2rWJjYy25DkECAAAHGjJkiBYsWKD33ntPoaGhOn78uCQpLCxMwcHBpl3H9kdkAwDgdHY82HL27NnKyMhQ586dFR0dXbAtXrzYjI9UgI4EAABWs2m0URroSAAAAMPoSAAAYDGz7tooiwgSAABYzI67NkoLow0AAGAYHQkAACzm4IYEQQIAAMs5OEkQJAAAsJiTF1uyRgIAABhGRwIAAIs5+a4NggQAABZzcI5gtAEAAIyjIwEAgMUYbQAAgCvg3CTBaAMAABhGRwIAAIsx2gAAAIY5OEcw2gAAAMbRkQAAwGKMNgAAgGFO/q4NggQAAFZzbo5gjQQAADCOjgQAABZzcEOCIAEAgNWcvNiS0QYAADCMjgQAABbjrg0AAGCcc3MEow0AAGAcHQkAACzm4IYEQQIAAKtx1wYAAEAR6EgAAGAx7toAAACGMdoAAAAoAkECAAAYxmgDAACLOXm0QZAAAMBiTl5syWgDAAAYRkcCAACLMdoAAACGOThHMNoAAADG0ZEAAMBqDm5JECQAALAYd20AAAAUgY4EAAAW464NAABgmINzBEECAADLOThJsEYCAAAHmzVrlurXr69KlSqpTZs22rJli6nnJ0gAAGAxl0m/Smrx4sVKSkrShAkTtH37djVr1kzdunXTyZMnTftsBAkAACzmcpmzldSLL76ogQMHqn///mrcuLFSUlJUuXJlvfHGG6Z9NoIEAADlhNfrVWZmpt/m9XqLfO/Fixe1bds2de3atWBfQECAunbtqo0bN5pWkyMXW1Zy5KcqGa/XK4/Ho+TkZLndbrvLsd2OCbfaXYLt+DOBX+LPQ+ky6++liX/xaNKkSX77JkyYoIkTJxZ6b3p6uvLy8lSzZk2//TVr1tSXX35pTkGSXD6fz2fa2VBmZGZmKiwsTBkZGapatard5aAM4M8Efok/D+WT1+st1IFwu91FhsGjR4/qmmuu0YYNG9SuXbuC/U8++aTWrVunzZs3m1IT/+8OAEA5canQUJTq1asrMDBQJ06c8Nt/4sQJ1apVy7SaWCMBAIADBQUFqWXLllqzZk3Bvvz8fK1Zs8avQ3Gl6EgAAOBQSUlJSkxMVKtWrXTzzTdr+vTpys7OVv/+/U27BkHCodxutyZMmMAiKhTgzwR+iT8PV4f/+Z//0alTpzR+/HgdP35cN910k1atWlVoAeaVYLElAAAwjDUSAADAMIIEAAAwjCABAAAMI0gAAADDCBIOZfXXxqL8SE1NVc+ePRUTEyOXy6Xly5fbXRJs5PF41Lp1a4WGhioqKkoJCQlKS0uzuyyUYwQJByqNr41F+ZGdna1mzZpp1qxZdpeCMmDdunUaMmSINm3apNWrVys3N1e33367srOz7S4N5RS3fzpQmzZt1Lp1a82cOVPSj08yq1OnjoYNG6axY8faXB3s5HK5tGzZMiUkJNhdCsqIU6dOKSoqSuvWrVPHjh3tLgflEB0Jhymtr40F4AwZGRmSpIiICJsrQXlFkHCYy31t7PHjx22qCkBZlJ+fr5EjR6pDhw5q2rSp3eWgnOIR2QBwlRoyZIi++OILrV+/3u5SUI4RJBymtL42FkD5NnToUK1cuVKpqamqXbu23eWgHGO04TCl9bWxAMonn8+noUOHatmyZfr4448VGxtrd0ko5+hIOFBpfG0syo+srCzt37+/4PWBAwe0c+dORUREqG7dujZWBjsMGTJECxYs0HvvvafQ0NCCtVNhYWEKDg62uTqUR9z+6VAzZ87UX//614KvjZ0xY4batGljd1mwwdq1a9WlS5dC+xMTEzVv3rzSLwi2crlcRe6fO3euHnroodItBo5AkAAAAIaxRgIAABhGkAAAAIYRJAAAgGEECQAAYBhBAgAAGEaQAAAAhhEkAACAYQQJAABgGEECcKCHHnpICQkJBa87d+6skSNHlnoda9eulcvl0rlz50r92gBKB0ECKEUPPfSQXC6XXC6XgoKC1KBBAz3zzDP64YcfLL3u0qVLNXny5GK9l7/8AZQEX9oFlLLu3btr7ty58nq9+uCDDzRkyBBVrFhRycnJfu+7ePGigoKCTLlmRESEKecBgF+jIwGUMrfbrVq1aqlevXoaNGiQunbtqhUrVhSMI6ZMmaKYmBg1bNhQknT48GH169dP1apVU0REhHr37q1vv/224Hx5eXlKSkpStWrVFBkZqSeffFK//gqdX482vF6vxowZozp16sjtdqtBgwaaM2eOvv3224Iv+AoPD5fL5Sr4Iqf8/Hx5PB7FxsYqODhYzZo107vvvut3nQ8++EA33HCDgoOD1aVLF786ATgTQQKwWXBwsC5evChJWrNmjdLS0rR69WqtXLlSubm56tatm0JDQ/Xpp5/qP//5j6pUqaLu3bsX/MwLL7ygefPm6Y033tD69et15swZLVu27LLXfPDBB7Vw4ULNmDFDe/fu1auvvqoqVaqoTp06WrJkiSQpLS1Nx44d09/+9jdJksfj0ZtvvqmUlBT997//1ahRo3T//fdr3bp1kn4MPH369FHPnj21c+dO/fnPf9bYsWOt+m0DUFb4AJSaxMREX+/evX0+n8+Xn5/vW716tc/tdvsef/xxX2Jioq9mzZo+r9db8P633nrL17BhQ19+fn7BPq/X6wsODvb961//8vl8Pl90dLRv2rRpBcdzc3N9tWvXLriOz+fzderUyTdixAifz+fzpaWl+ST5Vq9eXWSNn3zyiU+S7+zZswX7cnJyfJUrV/Zt2LDB770PP/yw79577/X5fD5fcnKyr3Hjxn7Hx4wZU+hcAJyFNRJAKVu5cqWqVKmi3Nxc5efn609/+pMmTpyoIUOGKD4+3m9dxK5du7R//36Fhob6nSMnJ0dff/21MjIydOzYMbVp06bgWIUKFdSqVatC442f7Ny5U4GBgerUqVOxa96/f7/Onz+v3//+9377L168qObNm0uS9u7d61eHJLVr167Y1wBQPhEkgFLWpUsXzZ49W0FBQYqJiVGFCj//axgSEuL33qysLLVs2VLvvPNOofPUqFHD0PWDg4NL/DNZWVmSpPfff1/XXHON3zG3222oDgDOQJAASllISIgaNGhQrPe2aNFCixcvVlRUlKpWrVrke6Kjo7V582Z17NhRkvTDDz9o27ZtatGiRZHvj4+PV35+vtatW6euXbsWOv5TRyQvL69gX+PGjeV2u3Xo0KFLdjIaNWqkFStW+O3btGnTb39IAOUaiy2BMuy+++5T9erV1bt3b3366ac6cOCA1q5dq+HDh+u7776TJI0YMULPPvusli9fri+//FKDBw++7DMg6tevr8TERA0YMEDLly8vOOc//vEPSVK9evXkcrm0cuVKnTp1SllZWQoNDdXjjz+uUaNGaf78+fr666+1fft2vfzyy5o/f74k6bHHHtNXX32lJ554QmlpaVqwYIHmzZtn9W8RAJsRJIAyrHLlykpNTVXdunXVp08fNWrUSA8//LBycnIKOhSjR4/WAw88oMTERLVr106hoaG66667Lnve2bNn6+6779bgwYMVFxengQMHKjs7W5J0zTXXaNKkSRo7dqxq1qypoUOHSpImT56scePGyePxqFGjRurevbvef/99xcbGSpLq1q2rJUuWaPny5WrWrJlSUlI0depUC393AJQFLt+lVmQBAAD8BjoSAADAMIIEAAAwjCABAAAMI0gAAADDCBIAAMAwggQAADCMIAEAAAwjSAAAAMMIEgAAwDCCBAAAMIwgAQAADPt/jvcHa7uq2DAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 12: Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "v5pF8coAh0_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 13: Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Generate imbalanced dataset (90% of class 0, 10% of class 1)\n",
        "y = np.hstack((np.zeros(180), np.ones(20)))\n",
        "np.random.shuffle(y)\n",
        "X = np.random.rand(200, 5)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model with class weights\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPDZnWjGiDiI",
        "outputId": "a3cc5e04-0370-46a8-cfd2-9b851fbb1ac2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 14: Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')[['sex', 'age', 'fare', 'pclass', 'survived']].dropna()\n",
        "\n",
        "# Convert categorical 'sex' to numerical\n",
        "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Split data\n",
        "X = df[['sex', 'age', 'fare', 'pclass']]\n",
        "y = df['survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle missing values and train model\n",
        "pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('model', LogisticRegression())])\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pipeline.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IbMgQIdiDkn",
        "outputId": "783470f0-ff12-49d9-de4d-d98095fc3687"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7552447552447552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 15: Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model.\n",
        "# Evaluate its accuracy and compare results with and without scaling.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X = np.random.rand(300, 5)\n",
        "y = np.random.randint(0, 2, 300)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Without scaling\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "acc_no_scaling = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "acc_scaling = accuracy_score(y_test, model_scaled.predict(X_test_scaled))\n",
        "\n",
        "print(\"Accuracy without scaling:\", acc_no_scaling)\n",
        "print(\"Accuracy with scaling:\", acc_scaling)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYqycPiYiDnI",
        "outputId": "51d8ac79-ee21-4367-e450-2786cbe909b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.6333333333333333\n",
            "Accuracy with scaling: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 16: Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Compute ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdTKHrjDiDpw",
        "outputId": "60079d19-c417-4b11-829a-20ea6b25a964"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.6318131256952169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 17: Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "\n",
        "# Train model with custom C\n",
        "model_custom = LogisticRegression(C=0.5)\n",
        "model_custom.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, model_custom.predict(X_test_scaled))\n",
        "print(\"Accuracy with C=0.5:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM59a_4miDuv",
        "outputId": "abb9d9be-0fab-43e1-81dc-840f1c476d79"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 18: Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print feature importance\n",
        "print(\"Feature Importance (Coefficients):\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQK9gDAFiDxI",
        "outputId": "62825ac4-4d88-4e12-f677-0bcb79a57aaf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance (Coefficients): [[0.13574474 0.12988621 0.19835398 0.17204567 0.13538168]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 19: Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score.\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Compute Cohen's Kappa Score\n",
        "kappa = cohen_kappa_score(y_test, model.predict(X_test_scaled))\n",
        "print(\"Cohen’s Kappa Score:\", kappa)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fwXZ1jViDzg",
        "outputId": "b396d02c-ef99-43c6-f3b0-256b2c62e00a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen’s Kappa Score: 0.19732441471571904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 20: Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "# Plot curve\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "TspUi7F0iD2I",
        "outputId": "fb37fa27-16f3-47b7-9e72-ff78c0461800"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 21: Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=500)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    accuracy = accuracy_score(y_test, model.predict(X_test_scaled))\n",
        "    print(f\"Accuracy with {solver} solver:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67_2J--siD43",
        "outputId": "833a403d-6ee1-4b2c-a450-758000c2123c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear solver: 0.6\n",
            "Accuracy with saga solver: 0.6\n",
            "Accuracy with lbfgs solver: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 22: Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Compute MCC\n",
        "mcc = matthews_corrcoef(y_test, model.predict(X_test_scaled))\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EpIxCjJiD7Y",
        "outputId": "e772dd49-17cc-4497-c0e3-e395532aa9e5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.19776733828108597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 23: Write a Python program to train Logistic Regression on both raw and standardized data.\n",
        "# Compare their accuracy to see the impact of feature scaling.\n",
        "\n",
        "print(\"Accuracy without scaling:\", acc_no_scaling)\n",
        "print(\"Accuracy with scaling:\", acc_scaling)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G892YqIiEBH",
        "outputId": "23edc3f3-c10e-4192-a32d-6c120ed4ab50"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.6333333333333333\n",
            "Accuracy with scaling: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 24: Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10]}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print best C value\n",
        "print(\"Best C:\", grid.best_params_['C'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObPwJUTKze2u",
        "outputId": "39624cf5-8784-43cd-f408-f1c3cc3faf8c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 25: Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, \"logistic_model.pkl\")\n",
        "\n",
        "# Load model\n",
        "loaded_model = joblib.load(\"logistic_model.pkl\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred_loaded = loaded_model.predict(X_test_scaled)\n",
        "print(\"Accuracy of loaded model:\", accuracy_score(y_test, y_pred_loaded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_dUnFoFzgyb",
        "outputId": "ecfccf4d-305f-453c-851e-f8704355aee6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of loaded model: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fArvoCQCzir9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}